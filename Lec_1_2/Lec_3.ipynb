{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01756feb",
   "metadata": {},
   "source": [
    "# Morphological Image processing \n",
    "معالجة الصور المورفولوجية هي تقنية غير خطية تستخدم علم التشكل الرياضي لتحليل ومعالجة الصور الرقمية. يعتمد على فكرة أن شكل وبنية كائن في صورة ما يمكن تمثيله باستخدام العمليات الحسابية.\n",
    "\n",
    "العناصر الأساسية لمعالجة الصور المورفولوجية هي عناصر هيكلية ، وهي عبارة عن أشكال صغيرة (عادة مربعات أو دوائر) تُستخدم لمسح صورة ضوئيًا ومقارنة وحدات البكسل بشكل عنصر الهيكلة. العمليات المورفولوجية الأكثر شيوعًا هي التعرية والتمدد والفتح والإغلاق.\n",
    "\n",
    "Erosion_ هي عملية تؤدي إلى تآكل حدود الكائن في الصورة ، مما يقلل من حجمها.\n",
    "\n",
    "  Dilation_ هي عملية تقوم بتوسيع حدود كائن في صورة ما ، مما يؤدي إلى زيادة حجمه.\n",
    "\n",
    "OPENING_ هي عملية تؤدي إلى تآكل الصورة ثم توسيعها ، مما يؤدي إلى إزالة وحدات البكسل الصغيرة المعزولة (التشويش) والفجوات الموجودة في الكائن.\n",
    "\n",
    "  __CLOSING__ هي عملية تقوم بتوسيع الصورة ثم تآكلها ، مما يؤدي إلى ملء الفجوات والثقوب الصغيرة في الكائن.\n",
    "\n",
    "يمكن تطبيق هذه العمليات على الصور الثنائية والصور ذات التدرج الرمادي والصور الملونة. يمكن استخدامها في مجموعة متنوعة من المهام ، مثل تجزئة الصورة وتقليل الضوضاء واكتشاف الكائنات واستعادة الصورة. بالإضافة إلى ذلك ، يمكن دمج معالجة الصور المورفولوجية مع تقنيات معالجة الصور الأخرى مثل التصفية ، والحد من الحواف واكتشاف الحواف لتحسين النتائج.\n",
    "\n",
    "تُستخدم معالجة الصور المورفولوجية على نطاق واسع في العديد من المجالات مثل التصوير الطبي والفحص الصناعي وتحليل صور الأقمار الصناعية ، من بين أمور أخرى. يسمح باستخراج ميزات الصورة ، والتي يصعب استخلاصها بطرق أخرى ، وتحليل شكل وهيكل الكائنات في الصورة"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ebe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fa8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"Trakpar.png\",0)\n",
    "_,mask=cv2.threshold(img,220,250,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "Kernal=np.ones((5,5),np.uint8)\n",
    "Kernal_=np.ones((3,3),np.uint8)\n",
    "dilation=cv2.dilate(mask,Kernal_,iterations=2)\n",
    "erosion=cv2.erode(dilation,Kernal,iterations=2)\n",
    "opening=cv2.morphologyEx(mask,cv2.MORPH_OPEN,Kernal,iterations=1)\n",
    "closing=cv2.morphologyEx(mask,cv2.MORPH_CLOSE,Kernal,iterations=1)\n",
    "\n",
    "\n",
    "cv2.imshow('Gray',img)\n",
    "cv2.imshow('Gray',mask)\n",
    "# cv2.imshow('dilation',dilation)\n",
    "# cv2.imshow('erosion',erosion)\n",
    "# cv2.imshow('opening',opening)\n",
    "# cv2.imshow('closing',closing)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ccf6b",
   "metadata": {},
   "source": [
    "# Somoothing or Blurring Images\n",
    "\n",
    "### are used to remove the noise from the images and it use diverse linear\n",
    "### because linear filter easy to achive and relatively fast \n",
    "\n",
    "### For example :-\n",
    "* Blur\n",
    "* Gaussian filter\n",
    "* Median Filter\n",
    "* Bilateral Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af6ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"Older.png\")\n",
    "  \n",
    "averaging=cv2.blur(img,(5,5))\n",
    "Gaussian_F=cv2.GaussianBlur(img,(5,5),0)\n",
    "median=cv2.medianBlur(img,5)\n",
    "Bilateral=cv2.bilateralFilter(img,9,75,75)\n",
    "\n",
    "cv2.imshow('Gray',img)\n",
    "# cv2.imshow('averaging',averaging)\n",
    "# cv2.imshow('Gaussian_F',Gaussian_F)\n",
    "# cv2.imshow('median',median)\n",
    "# cv2.imshow('Bilateral',Bilateral)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224daeba",
   "metadata": {},
   "source": [
    "# Edge Detection using Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84754ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=cv2.imread(\"mesi.png\")\n",
    "\n",
    "lap=cv2.Laplacian(img,cv2.CV_64F,ksize=3)\n",
    "lap=np.uint8(np.absolute(lap))\n",
    "\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('Lapacian',lap)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd415f4",
   "metadata": {},
   "source": [
    "# Sobel X and Sobel Y edge detecion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "603b9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=cv2.imread(\"mesi.png\")\n",
    "\n",
    "sobel_X=cv2.Sobel(img,cv2.CV_64F,1,0)\n",
    "sobel_Y=cv2.Sobel(img,cv2.CV_64F,0,1)\n",
    "sobel_X=np.uint8(np.absolute(sobel_X))\n",
    "sobel_Y=np.uint8(np.absolute(sobel_Y))\n",
    "\n",
    "comine_sobel_X_and_Y=cv2.bitwise_or(sobel_X,sobel_Y)\n",
    "\n",
    "cv2.imshow('Gray',img)\n",
    "cv2.imshow('sobel_X',sobel_X)\n",
    "cv2.imshow('sobel_Y',sobel_Y)\n",
    "cv2.imshow('comine_sobel_X_and_Y',comine_sobel_X_and_Y)\n",
    "# cv2.imshow('Bilateral',Bilateral)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff0301",
   "metadata": {},
   "source": [
    "# Canny Edge Detection\n",
    "### 1- convert image to gray scale \n",
    "### 2- remove the noise from the image by using gaussian filter which discuss befor \n",
    "### 3- use sobel X and Sobel Y to get the edges in two directions and combine them by using (Edge_Gradient)\n",
    "### 4- apply Non-Maximum Suppression to make the edges thin\n",
    "### 5- Hysteresis Thresholding to connect the strong edges and ignor other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4792d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=cv2.imread(\"mesi.png\")\n",
    "\n",
    "canny=cv2.Canny(img,100,100)\n",
    "cv2.imshow('canny',canny)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffb280",
   "metadata": {},
   "source": [
    " # image pyramid (Gaussin pyramid and Laplacian pyrmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b44b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=cv2.imread(\"mesi.png\")\n",
    "lr1=cv2.pyrDown(img)\n",
    "lr2=cv2.pyrDown(lr1)\n",
    "hr2=cv2.pyrDown(lr2)\n",
    "pr=cv2.pyrUp(lr2)\n",
    "cv2.imshow(\"Original image \",img)\n",
    "cv2.imshow(\"lr1 \",lr1)\n",
    "cv2.imshow(\"lr2 \",lr2)\n",
    "cv2.imshow(\"hr2\",pr)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eb2eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=cv2.imread(\"mesi.png\")\n",
    "layer=img.copy()\n",
    "gp=[layer]\n",
    "\n",
    "for i in range(4):\n",
    "    layer =cv2.pyrDown(layer)\n",
    "    gp.append(layer)\n",
    "    cv2.imshow(str(i),layer)\n",
    "    \n",
    "cv2.imshow(\"Original image \",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa80365",
   "metadata": {},
   "source": [
    "# find and draw contours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3bc6db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours = 14\n",
      "[[[272 409]]\n",
      "\n",
      " [[271 410]]\n",
      "\n",
      " [[270 411]]\n",
      "\n",
      " [[269 411]]\n",
      "\n",
      " [[268 412]]\n",
      "\n",
      " [[267 412]]\n",
      "\n",
      " [[266 411]]\n",
      "\n",
      " [[265 411]]\n",
      "\n",
      " [[264 411]]\n",
      "\n",
      " [[263 411]]\n",
      "\n",
      " [[262 411]]\n",
      "\n",
      " [[261 411]]\n",
      "\n",
      " [[260 411]]\n",
      "\n",
      " [[259 411]]\n",
      "\n",
      " [[259 412]]\n",
      "\n",
      " [[259 413]]\n",
      "\n",
      " [[259 414]]\n",
      "\n",
      " [[259 415]]\n",
      "\n",
      " [[259 416]]\n",
      "\n",
      " [[259 417]]\n",
      "\n",
      " [[259 418]]\n",
      "\n",
      " [[259 419]]\n",
      "\n",
      " [[259 420]]\n",
      "\n",
      " [[259 421]]\n",
      "\n",
      " [[259 422]]\n",
      "\n",
      " [[259 423]]\n",
      "\n",
      " [[259 424]]\n",
      "\n",
      " [[259 425]]\n",
      "\n",
      " [[259 426]]\n",
      "\n",
      " [[259 427]]\n",
      "\n",
      " [[259 428]]\n",
      "\n",
      " [[259 429]]\n",
      "\n",
      " [[259 430]]\n",
      "\n",
      " [[259 431]]\n",
      "\n",
      " [[259 432]]\n",
      "\n",
      " [[259 433]]\n",
      "\n",
      " [[259 434]]\n",
      "\n",
      " [[259 435]]\n",
      "\n",
      " [[259 436]]\n",
      "\n",
      " [[259 437]]\n",
      "\n",
      " [[259 438]]\n",
      "\n",
      " [[259 439]]\n",
      "\n",
      " [[259 440]]\n",
      "\n",
      " [[259 441]]\n",
      "\n",
      " [[259 442]]\n",
      "\n",
      " [[259 443]]\n",
      "\n",
      " [[259 444]]\n",
      "\n",
      " [[259 445]]\n",
      "\n",
      " [[259 446]]\n",
      "\n",
      " [[259 447]]\n",
      "\n",
      " [[259 448]]\n",
      "\n",
      " [[259 449]]\n",
      "\n",
      " [[259 450]]\n",
      "\n",
      " [[259 451]]\n",
      "\n",
      " [[259 452]]\n",
      "\n",
      " [[259 453]]\n",
      "\n",
      " [[259 454]]\n",
      "\n",
      " [[259 455]]\n",
      "\n",
      " [[259 456]]\n",
      "\n",
      " [[259 457]]\n",
      "\n",
      " [[259 458]]\n",
      "\n",
      " [[259 459]]\n",
      "\n",
      " [[259 460]]\n",
      "\n",
      " [[259 461]]\n",
      "\n",
      " [[260 462]]\n",
      "\n",
      " [[261 463]]\n",
      "\n",
      " [[262 463]]\n",
      "\n",
      " [[263 463]]\n",
      "\n",
      " [[264 463]]\n",
      "\n",
      " [[265 462]]\n",
      "\n",
      " [[266 462]]\n",
      "\n",
      " [[266 461]]\n",
      "\n",
      " [[266 460]]\n",
      "\n",
      " [[267 459]]\n",
      "\n",
      " [[267 458]]\n",
      "\n",
      " [[267 457]]\n",
      "\n",
      " [[267 456]]\n",
      "\n",
      " [[267 455]]\n",
      "\n",
      " [[267 454]]\n",
      "\n",
      " [[267 453]]\n",
      "\n",
      " [[267 452]]\n",
      "\n",
      " [[267 451]]\n",
      "\n",
      " [[267 450]]\n",
      "\n",
      " [[267 449]]\n",
      "\n",
      " [[267 448]]\n",
      "\n",
      " [[267 447]]\n",
      "\n",
      " [[267 446]]\n",
      "\n",
      " [[267 445]]\n",
      "\n",
      " [[267 444]]\n",
      "\n",
      " [[267 443]]\n",
      "\n",
      " [[267 442]]\n",
      "\n",
      " [[267 441]]\n",
      "\n",
      " [[267 440]]\n",
      "\n",
      " [[267 439]]\n",
      "\n",
      " [[267 438]]\n",
      "\n",
      " [[267 437]]\n",
      "\n",
      " [[267 436]]\n",
      "\n",
      " [[267 435]]\n",
      "\n",
      " [[267 434]]\n",
      "\n",
      " [[267 433]]\n",
      "\n",
      " [[267 432]]\n",
      "\n",
      " [[267 431]]\n",
      "\n",
      " [[267 430]]\n",
      "\n",
      " [[267 429]]\n",
      "\n",
      " [[267 428]]\n",
      "\n",
      " [[268 427]]\n",
      "\n",
      " [[268 426]]\n",
      "\n",
      " [[268 425]]\n",
      "\n",
      " [[269 424]]\n",
      "\n",
      " [[270 423]]\n",
      "\n",
      " [[271 423]]\n",
      "\n",
      " [[272 423]]\n",
      "\n",
      " [[273 423]]\n",
      "\n",
      " [[274 423]]\n",
      "\n",
      " [[275 424]]\n",
      "\n",
      " [[275 425]]\n",
      "\n",
      " [[276 426]]\n",
      "\n",
      " [[276 427]]\n",
      "\n",
      " [[276 428]]\n",
      "\n",
      " [[276 429]]\n",
      "\n",
      " [[276 430]]\n",
      "\n",
      " [[276 431]]\n",
      "\n",
      " [[276 432]]\n",
      "\n",
      " [[276 433]]\n",
      "\n",
      " [[276 434]]\n",
      "\n",
      " [[276 435]]\n",
      "\n",
      " [[276 436]]\n",
      "\n",
      " [[276 437]]\n",
      "\n",
      " [[276 438]]\n",
      "\n",
      " [[276 439]]\n",
      "\n",
      " [[276 440]]\n",
      "\n",
      " [[276 441]]\n",
      "\n",
      " [[276 442]]\n",
      "\n",
      " [[276 443]]\n",
      "\n",
      " [[276 444]]\n",
      "\n",
      " [[276 445]]\n",
      "\n",
      " [[276 446]]\n",
      "\n",
      " [[276 447]]\n",
      "\n",
      " [[276 448]]\n",
      "\n",
      " [[276 449]]\n",
      "\n",
      " [[276 450]]\n",
      "\n",
      " [[276 451]]\n",
      "\n",
      " [[276 452]]\n",
      "\n",
      " [[276 453]]\n",
      "\n",
      " [[276 454]]\n",
      "\n",
      " [[276 455]]\n",
      "\n",
      " [[276 456]]\n",
      "\n",
      " [[276 457]]\n",
      "\n",
      " [[276 458]]\n",
      "\n",
      " [[276 459]]\n",
      "\n",
      " [[276 460]]\n",
      "\n",
      " [[276 461]]\n",
      "\n",
      " [[277 462]]\n",
      "\n",
      " [[278 463]]\n",
      "\n",
      " [[279 463]]\n",
      "\n",
      " [[280 463]]\n",
      "\n",
      " [[281 463]]\n",
      "\n",
      " [[282 463]]\n",
      "\n",
      " [[283 462]]\n",
      "\n",
      " [[283 461]]\n",
      "\n",
      " [[283 460]]\n",
      "\n",
      " [[283 459]]\n",
      "\n",
      " [[283 458]]\n",
      "\n",
      " [[283 457]]\n",
      "\n",
      " [[284 456]]\n",
      "\n",
      " [[284 455]]\n",
      "\n",
      " [[284 454]]\n",
      "\n",
      " [[283 453]]\n",
      "\n",
      " [[283 452]]\n",
      "\n",
      " [[283 451]]\n",
      "\n",
      " [[283 450]]\n",
      "\n",
      " [[283 449]]\n",
      "\n",
      " [[283 448]]\n",
      "\n",
      " [[283 447]]\n",
      "\n",
      " [[283 446]]\n",
      "\n",
      " [[283 445]]\n",
      "\n",
      " [[283 444]]\n",
      "\n",
      " [[283 443]]\n",
      "\n",
      " [[283 442]]\n",
      "\n",
      " [[284 441]]\n",
      "\n",
      " [[284 440]]\n",
      "\n",
      " [[283 439]]\n",
      "\n",
      " [[283 438]]\n",
      "\n",
      " [[283 437]]\n",
      "\n",
      " [[283 436]]\n",
      "\n",
      " [[283 435]]\n",
      "\n",
      " [[283 434]]\n",
      "\n",
      " [[283 433]]\n",
      "\n",
      " [[283 432]]\n",
      "\n",
      " [[283 431]]\n",
      "\n",
      " [[283 430]]\n",
      "\n",
      " [[283 429]]\n",
      "\n",
      " [[283 428]]\n",
      "\n",
      " [[283 427]]\n",
      "\n",
      " [[283 426]]\n",
      "\n",
      " [[283 425]]\n",
      "\n",
      " [[283 424]]\n",
      "\n",
      " [[283 423]]\n",
      "\n",
      " [[283 422]]\n",
      "\n",
      " [[283 421]]\n",
      "\n",
      " [[283 420]]\n",
      "\n",
      " [[283 419]]\n",
      "\n",
      " [[283 418]]\n",
      "\n",
      " [[283 417]]\n",
      "\n",
      " [[282 416]]\n",
      "\n",
      " [[282 415]]\n",
      "\n",
      " [[281 414]]\n",
      "\n",
      " [[281 413]]\n",
      "\n",
      " [[280 412]]\n",
      "\n",
      " [[279 411]]\n",
      "\n",
      " [[278 411]]\n",
      "\n",
      " [[277 411]]\n",
      "\n",
      " [[276 410]]\n",
      "\n",
      " [[275 409]]\n",
      "\n",
      " [[274 409]]\n",
      "\n",
      " [[273 409]]]\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('log.png')\n",
    "img=cv2.resize(img,(512,512))\n",
    "imgray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh=cv2.threshold(imgray,20,255,0)\n",
    "contours,hierarchy=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE )\n",
    " \n",
    "print(\"Number of contours = \"+str(len(contours)))\n",
    "print(contours[0])\n",
    "cv2.drawContours(img,contours,-1,(0,255,0),3)\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.imshow('Image gray',imgray)\n",
    "cv2.imshow(\"thresh\",thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506d7551",
   "metadata": {},
   "source": [
    "# Motion Detection  and Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de0e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap=cv2.VideoCapture(1)\n",
    "\n",
    "fram_width=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc=cv2.VideoWriter_fourcc(*'XVID')\n",
    "out=cv2.VideoWriter(\"Detect.avi\",fourcc,30,(1280,720))\n",
    "            \n",
    "ret,frame_1=cap.read()\n",
    "ret,frame_2=cap.read()\n",
    "while cap.isOpened():\n",
    "        diff=cv2.absdiff(frame_1,frame_2)\n",
    "        gray=cv2.cvtColor(diff,cv2.COLOR_BGR2GRAY)\n",
    "        blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "        \n",
    "        _,threshould=cv2.threshold(blur,60,255,cv2.THRESH_BINARY)\n",
    "        dilated=cv2.dilate(threshould,None,iterations=10)\n",
    "        contours,_=cv2.findContours(dilated,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "        draw=cv2.drawContours(frame_1,contours,-1,(0,255,0),2)\n",
    "\n",
    "        for contour in contours:\n",
    "            (x,y,w,h)=cv2.boundingRect(contour)\n",
    "            \n",
    "            if cv2.contourArea(contour)<900:\n",
    "                 continue\n",
    "            cv2.rectangle(frame_1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(frame_1,\"Status : movement\",(10,20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "                 \n",
    "        image=cv2.resize(frame_1,(1280,720))\n",
    "        out.write(image)\n",
    "        cv2.imshow(\"Motion detection\",frame_1)\n",
    "                \n",
    "        cv2.imshow(\"threshould \",threshould)\n",
    "        cv2.imshow(\"dilated \",dilated)\n",
    "                 \n",
    "        frame_1=frame_2\n",
    "        ret,frame_2=cap.read()\n",
    "                 \n",
    "        if cv2.waitKey(60)==27:\n",
    "                 break\n",
    "\n",
    "                 \n",
    "     \n",
    "cv2.destroyAllWindows()              \n",
    "cap.release()               \n",
    "out.release()               \n",
    "                 \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6e39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540103fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f28cae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16506a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
